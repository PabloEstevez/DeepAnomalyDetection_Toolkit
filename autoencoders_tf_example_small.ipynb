{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import dataset\n",
    "dataset = pd.read_csv(\"../Datasets/EU-SEN_dataset.csv\")\n",
    "\n",
    "# Delete unwanted features\n",
    "dataset.drop(['country'], axis=1, inplace=True)\n",
    "\n",
    "#print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Autoscaling\n",
    "xc = StandardScaler().fit_transform(dataset)\n",
    "\n",
    "# Dataset split (train & test)\n",
    "X_train = xc[0:len(xc)-1, :] # Europe\n",
    "X_test = xc[len(xc)-1:len(xc),:] # Senegal\n",
    "#X_test = xc[6:7,:] # Poland\n",
    "Y_test = np.ones((len(X_test),1))\n",
    "# X_train, X_test = train_test_split(xc, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 12:14:39.601051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-06 12:14:39.601070: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 12:14:40.606847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-06 12:14:40.607063: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-06 12:14:40.607125: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-06 12:14:40.607168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-06 12:14:40.607209: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-06 12:14:40.607250: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-03-06 12:14:40.607289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-06 12:14:40.607327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-06 12:14:40.607366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-03-06 12:14:40.607372: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-06 12:14:40.607612: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/abelop/.local/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 0.9834 - val_loss: 0.9745\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9720 - val_loss: 0.9635\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9625 - val_loss: 0.9583\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9591 - val_loss: 0.9567\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9547 - val_loss: 0.9520\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9527 - val_loss: 0.9489\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9484 - val_loss: 0.9458\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9461 - val_loss: 0.9431\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 0.9404\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9410 - val_loss: 0.9384\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9385 - val_loss: 0.9355\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9363 - val_loss: 0.9343\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9346 - val_loss: 0.9324\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.9310\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9316 - val_loss: 0.9299\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9304 - val_loss: 0.9288\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9290 - val_loss: 0.9270\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9274 - val_loss: 0.9253\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9255 - val_loss: 0.9237\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9238 - val_loss: 0.9222\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9224 - val_loss: 0.9208\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9210 - val_loss: 0.9196\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.9200 - val_loss: 0.9182\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9183 - val_loss: 0.9170\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9174 - val_loss: 0.9160\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9164 - val_loss: 0.9151\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9153 - val_loss: 0.9143\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9146 - val_loss: 0.9135\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9139 - val_loss: 0.9128\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9131 - val_loss: 0.9121\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9125 - val_loss: 0.9115\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9121 - val_loss: 0.9111\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9115 - val_loss: 0.9103\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9106 - val_loss: 0.9097\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9101 - val_loss: 0.9092\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9096 - val_loss: 0.9087\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9090 - val_loss: 0.9082\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9085 - val_loss: 0.9079\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9082 - val_loss: 0.9079\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9082 - val_loss: 0.9072\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9076 - val_loss: 0.9068\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9073 - val_loss: 0.9064\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9069 - val_loss: 0.9061\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9064 - val_loss: 0.9057\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9062 - val_loss: 0.9054\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9056 - val_loss: 0.9051\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9056 - val_loss: 0.9049\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.9051 - val_loss: 0.9042\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9046 - val_loss: 0.9037\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.9042 - val_loss: 0.9035\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9041 - val_loss: 0.9030\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9033 - val_loss: 0.9023\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9026 - val_loss: 0.9018\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9022 - val_loss: 0.9014\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9019 - val_loss: 0.9010\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9014 - val_loss: 0.9005\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9009 - val_loss: 0.9002\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.9007 - val_loss: 0.8998\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.9002 - val_loss: 0.8994\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8999 - val_loss: 0.8997\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8998 - val_loss: 0.8988\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8993 - val_loss: 0.8984\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8989 - val_loss: 0.8980\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8985 - val_loss: 0.8977\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8982 - val_loss: 0.8973\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8978 - val_loss: 0.8968\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8973 - val_loss: 0.8964\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8969 - val_loss: 0.8959\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8965 - val_loss: 0.8955\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8960 - val_loss: 0.8951\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.8955 - val_loss: 0.8948\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8952 - val_loss: 0.8944\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8947 - val_loss: 0.8940\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8944 - val_loss: 0.8936\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8940 - val_loss: 0.8933\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8938 - val_loss: 0.8945\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8945 - val_loss: 0.8928\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8932 - val_loss: 0.8932\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8932 - val_loss: 0.8924\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8927 - val_loss: 0.8919\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8923 - val_loss: 0.8916\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8921 - val_loss: 0.8913\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8918 - val_loss: 0.8910\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8914 - val_loss: 0.8907\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8911 - val_loss: 0.8904\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8908 - val_loss: 0.8901\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8905 - val_loss: 0.8898\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8901 - val_loss: 0.8897\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.8901 - val_loss: 0.8893\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.8898 - val_loss: 0.8890\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8893 - val_loss: 0.8887\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.8890 - val_loss: 0.8883\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8883 - val_loss: 0.8879\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8881 - val_loss: 0.8875\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8879 - val_loss: 0.8871\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8875 - val_loss: 0.8868\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8873 - val_loss: 0.8865\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8869 - val_loss: 0.8868\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8871 - val_loss: 0.8858\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.8861 - val_loss: 0.8854\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "dim_entrada = X_train.shape[1]\n",
    "capa_entrada = Input(shape=(dim_entrada,))\n",
    "\n",
    "encoder = Dense(7, activation='tanh')(capa_entrada)\n",
    "encoder = Dense(2, activation='relu')(encoder)\n",
    "\n",
    "decoder = Dense(7, activation='tanh')(encoder)\n",
    "decoder = Dense(dim_entrada, activation='relu')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=capa_entrada, outputs=decoder)\n",
    "\n",
    "sgd = SGD(lr=0.01) # Learning Rate\n",
    "autoencoder.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "nits = 100\n",
    "tam_lote = 2\n",
    "autoencoder.fit(xc, xc, epochs=nits, batch_size=tam_lote, shuffle=True, validation_data=(xc,xc), verbose=1)\n",
    "\n",
    "plot_model(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:  [[1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "\n",
    "# Prediction X_test -> Autoencoder -> X_pred\n",
    "X_pred = autoencoder.predict(X_test)\n",
    "ecm = np.mean(np.power(X_test-X_pred,2), axis=1)\n",
    "print(X_pred.shape)\n",
    "\n",
    "# Precision-recall graph to determine threshold\n",
    "precision, recall, threshold = precision_recall_curve(Y_test, ecm)\n",
    "\n",
    "plt.plot(threshold, precision[1:], label=\"Precision\",linewidth=5)\n",
    "plt.plot(threshold, recall[1:], label=\"Recall\",linewidth=5)\n",
    "plt.title('Precision & Recall to differentiate the threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision/Recall')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "fixed_threshold = 0.75\n",
    "Y_pred = [1 if e > fixed_threshold else 0 for e in ecm]\n",
    "\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"Confusion matrix: \", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e38c271043618fdabfcd731a22bd25018a77cb3c7078e3658069e5fd357b7b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
